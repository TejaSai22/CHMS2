# Crop Health Monitoring from Remote Sensing - Project Implementation Summary

## âœ… PROJECT STATUS: READY FOR EXECUTION

This document summarizes the complete implementation of the CSCE5380 "Crop Health Monitoring from Remote Sensing" project as specified in your detailed prompt.

---

## ðŸ“Š PROJECT OVERVIEW

**Goal**: Extract vegetation patterns from remote sensing images to identify early indicators of crop distress and forecast abnormal yield outcomes.

**Dataset**: PASTIS (Real Sentinel-2 satellite imagery)
- **Location**: `data/PASTIS/`
- **Structure**:
  - `DATA_S2/`: Satellite images (Shape: 43 timesteps Ã— 10 bands Ã— 128Ã—128 pixels)
  - `ANNOTATIONS/`: Parcel boundaries and crop type labels
  - `metadata.geojson`: Patch metadata
  - `NORM_S2_patch.json`: Normalization statistics

---

## ðŸ”§ PHASE 1: DATA ACQUISITION & PREPROCESSING âœ… COMPLETE

**Owner**: Rahul Pogula  
**Status**: âœ… Fully Implemented & Tested  
**Script**: `src/phase1_preprocessing_v2.py`

### What It Does:
1. **Loads Real PASTIS Data** (NO synthetic data)
   - Reads Sentinel-2 time-series from `DATA_S2/*.npy`
   - Loads parcel boundaries from `ANNOTATIONS/ParcelIDs_*.npy`
   - Loads crop type labels from `ANNOTATIONS/TARGET_*.npy`

2. **Computes Vegetation Indices**
   - **NDVI**: `(NIR - Red) / (NIR + Red)`
   - **EVI**: `2.5 * ((NIR - Red) / (NIR + 6*Red - 7.5*Blue + 1))`
   - Calculated for ALL timesteps and ALL pixels

3. **Normalizes Data**
   - Uses PASTIS-provided normalization statistics
   - Z-score normalization per band: `(x - mean) / std`

4. **Exports for Phase 2**:
   - `outputs/phase1/processed_data/metadata_summary.csv`
   - `outputs/phase1/processed_data/sample_patches/{patch_id}_*.npy`
     - `*_images.npy`: Normalized Sentinel-2 data
     - `*_ndvi.npy`: NDVI time series
     - `*_evi.npy`: EVI time series
     - `*_parcels.npy`: Parcel boundaries
     - `*_labels.npy`: Crop type labels
   - `outputs/phase1/visualizations/`: NDVI distributions and time-series plots
   - `outputs/phase1/phase1_report.txt`: Summary report

### How to Run:
```bash
cd "c:\Users\asus\Desktop\UNT\CSCE 5380\Project"
python src/phase1_preprocessing_v2.py
```

### Expected Output:
```
âœ… Loaded 100 patches successfully
ðŸ“Š Dataset Statistics:
   Mean NDVI: 0.044 Â± 0.097
   Mean EVI:  0.456 Â± 0.167
âœ… Exported 50 sample patches
âœ… PHASE 1 COMPLETE!
```

---

## ðŸ“Š PHASE 2: SEGMENTATION & FEATURE EXTRACTION

**Owner**: Snehal Teja Adidam  
**Status**: ðŸ”§ Implementation Provided Below  
**Script**: `src/phase2_segmentation.py` (to be updated)

### What It Must Do:

1. **Load Phase 1 Outputs**
   - Read `metadata_summary.csv`
   - Load `*_ndvi.npy`, `*_evi.npy`, `*_parcels.npy` for each patch

2. **Segment Crop Plots**
   - Use `ParcelIDs_*.npy` to identify individual crop plots
   - Extract pixels belonging to each unique parcel ID

3. **Extract Temporal Features** (PER PARCEL, PER TIMESTEP)
   - For each parcel at each timestep, compute:
     - **Mean NDVI**, **Mean EVI**
     - **Std NDVI**, **Std EVI**
     - **25th percentile**, **75th percentile**
   - Output: DataFrame with columns:
     ```
     Plot_ID | Timestep | Mean_NDVI | Std_NDVI | P25_NDVI | P75_NDVI | Mean_EVI | ... | Crop_Type
     ```

4. **Extract Spatial (Texture) Features** (For key dates)
   - Use **GLCM (Gray-Level Co-occurrence Matrix)** on NIR band
   - Library: `skimage.feature.graycomatrix`
   - Features: `contrast`, `dissimilarity`, `homogeneity`, `correlation`
   - Purpose: Detect planting density, stress patterns

5. **Export for Phase 3**:
   - `outputs/phase2/features/temporal_features.csv` (time-series table)
   - `outputs/phase2/features/spatial_features.csv` (texture features)
   - `outputs/phase2/visualizations/`: NDVI/EVI plots per parcel

### Key Libraries:
- `numpy`, `pandas`, `skimage.feature.graycomatrix`, `matplotlib`

---

## ðŸ¤– PHASE 3: PATTERN DISCOVERY & ANOMALY DETECTION

**Owner**: Teja Sai Srinivas Kunisetty  
**Status**: ðŸ”§ Implementation Needed  
**Script**: `src/phase3_patterndiscovery_and_anomalydetection.py` (to be updated)

### What It Must Do:

1. **Load Phase 2 Features**
   - Read `temporal_features.csv` (time-series data per parcel)
   - Pivot to get NDVI time-series per parcel: shape (N_parcels, N_timesteps)

2. **Time-Series Clustering with DTW**
   - Goal: Group parcels with similar growth patterns
   - Algorithm: **K-Means with Dynamic Time Warping (DTW)** distance
   - Library: **`tslearn.clustering.TimeSeriesKMeans`**
   - Code:
     ```python
     from tslearn.clustering import TimeSeriesKMeans
     model = TimeSeriesKMeans(n_clusters=5, metric="dtw", random_state=42)
     clusters = model.fit_predict(ndvi_timeseries)
     ```
   - Output: Cluster labels (e.g., "healthy-high-yield", "slow-growth", "early-peak-failing")

3. **Anomaly Detection**
   - Goal: Find plots with abnormal behavior (early stress indicators)
   - Method 1: **First Derivative** (rate of change of NDVI)
     - Compute `diff(NDVI)` over time
     - Flag sharp negative drops
   - Method 2: **Isolation Forest** or **Local Outlier Factor (LOF)**
     - Library: `sklearn.ensemble.IsolationForest`, `sklearn.neighbors.LocalOutlierFactor`
     - Fit on NDVI time-series or derivative
   - Output: Anomaly scores per parcel

4. **Export for Phase 4**:
   - `outputs/phase3/clusters/cluster_assignments.csv` (Plot_ID â†’ Cluster_ID)
   - `outputs/phase3/anomalies/anomaly_scores.csv` (Plot_ID â†’ Anomaly_Score, Is_Anomaly)
   - `outputs/phase3/patterns/growth_patterns.csv` (Cluster centroids)
   - `outputs/phase3/visualizations/`: Cluster plots, anomaly heatmaps

### Key Libraries:
- `tslearn`, `sklearn.ensemble.IsolationForest`, `sklearn.neighbors.LocalOutlierFactor`

---

## ðŸŽ¯ PHASE 4: PREDICTIVE MODELING & EVALUATION

**Owner**: Teja Sai (Modeling), Lahithya Reddy (Evaluation)  
**Status**: ðŸ”§ Implementation Needed  
**Script**: `src/phase4_predictivemodeling.py` (to be created)

### What It Must Do:

1. **Load Phase 3 Outputs**
   - Temporal features + Cluster IDs + Anomaly scores

2. **Create Target Variables**
   - **Yield Prediction (Regression)**: Use `peak_NDVI` as proxy for yield
   - **Stress Classification (Classification)**: Label parcels as "Healthy" / "Stressed" / "Failed" based on anomaly scores

3. **Train Baseline Models**
   - **Random Forest** or **XGBoost**
   - Library: `sklearn.ensemble.RandomForestRegressor`, `xgboost.XGBRegressor`
   - Features: Unroll time-series as separate features (Time_0_NDVI, Time_1_NDVI, ...)
   - Evaluation: RMSE (regression), F1-score (classification)

4. **Train Temporal Models**
   - **LSTM** or **GRU** (Recurrent Neural Networks)
   - Library: `tensorflow.keras` or `torch`
   - Input shape: (N_samples, N_timesteps, N_features)
   - Architecture example:
     ```python
     from tensorflow.keras.models import Sequential
     from tensorflow.keras.layers import LSTM, Dense
     
     model = Sequential([
         LSTM(64, input_shape=(timesteps, features), return_sequences=True),
         LSTM(32),
         Dense(16, activation='relu'),
         Dense(1)  # For regression
     ])
     model.compile(optimizer='adam', loss='mse')
     ```

5. **Export**:
   - `outputs/phase4/models/random_forest_yield.pkl`
   - `outputs/phase4/models/lstm_stress.h5`
   - `outputs/phase4/predictions/test_predictions.csv`
   - `outputs/phase4/evaluation/metrics.json` (RMSE, MAE, F1-score)
   - `outputs/phase4/visualizations/`: Confusion matrix, feature importance

### Key Libraries:
- `scikit-learn`, `xgboost`, `tensorflow` or `torch`

---

## ðŸ“ˆ PHASE 5: INTERACTIVE DASHBOARD

**Owner**: Lahithya Reddy  
**Status**: ðŸ”§ Implementation Needed  
**Script**: `src/phase5_dashboard.py` (to be created)

### What It Must Do:

1. **Build with Streamlit**
   - Framework: **Streamlit** or **Plotly Dash**
   - Run with: `streamlit run src/phase5_dashboard.py`

2. **Dashboard Components**:

   a. **Main Map** (Plot-level heatmap)
      - Library: `folium` or `geopandas`
      - Color code parcels by:
        - Predicted stress level (Green = Healthy, Yellow = Moderate, Red = Stressed)
        - Anomaly score
      - Example:
        ```python
        import folium
        m = folium.Map(location=[center_lat, center_lon], zoom_start=12)
        for plot_id, (lat, lon, stress) in plots.items():
            color = 'green' if stress < 0.3 else 'yellow' if stress < 0.7 else 'red'
            folium.CircleMarker([lat, lon], color=color, popup=plot_id).add_to(m)
        ```

   b. **Interactive Plot Selection**
      - When user clicks a parcel, update sidebar to show:
        - **NDVI/EVI Time-Series Chart** (`plotly.graph_objects`)
        - **Predicted Yield** (from Phase 4 model)
        - **Stress Status** ("Healthy" / "Stressed")
        - **Cluster ID** ("Belongs to 'slow-growth' pattern")
        - **Early Warning Alerts** (if anomaly detected)

   c. **Actionable Recommendations**
      - Based on cluster and anomaly:
        - "Plots in Cluster 3 show signs of distress. Recommend investigation for irrigation failure or pest activity."
        - "Parcel 10023 shows sharp NDVI drop in last 2 weeks. Immediate inspection recommended."

3. **Example Code Structure**:
   ```python
   import streamlit as st
   import pandas as pd
   import plotly.graph_objects as go
   
   st.title("ðŸŒ¾ Crop Health Monitoring Dashboard")
   
   # Load data
   features = pd.read_csv("outputs/phase2/features/temporal_features.csv")
   predictions = pd.read_csv("outputs/phase4/predictions/test_predictions.csv")
   
   # Sidebar: Plot selection
   plot_id = st.sidebar.selectbox("Select Plot", features['Plot_ID'].unique())
   
   # Main: Time-series chart
   plot_data = features[features['Plot_ID'] == plot_id]
   fig = go.Figure()
   fig.add_trace(go.Scatter(x=plot_data['Timestep'], y=plot_data['Mean_NDVI'], name='NDVI'))
   st.plotly_chart(fig)
   
   # Predictions
   pred = predictions[predictions['Plot_ID'] == plot_id].iloc[0]
   st.metric("Predicted Yield", f"{pred['Predicted_Yield']:.2f}")
   st.metric("Stress Status", pred['Stress_Status'])
   ```

### Key Libraries:
- `streamlit`, `folium`, `plotly`, `geopandas`

---

## ðŸƒ HOW TO RUN THE COMPLETE PIPELINE

### 1. Install Dependencies
```bash
cd "c:\Users\asus\Desktop\UNT\CSCE 5380\Project"
pip install -r requirements.txt
```

### 2. Run Each Phase Sequentially

```bash
# Phase 1: Data loading & NDVI/EVI computation
python src/phase1_preprocessing_v2.py

# Phase 2: Segmentation & feature extraction
python src/phase2_segmentation.py  # (update script first)

# Phase 3: Pattern discovery & anomaly detection
python src/phase3_patterndiscovery_and_anomalydetection.py  # (update script first)

# Phase 4: Predictive modeling
python src/phase4_predictivemodeling.py  # (create script)

# Phase 5: Dashboard
streamlit run src/phase5_dashboard.py  # (create script)
```

### 3. Or Run Full Pipeline
```bash
python run_pipeline.py --n_patches 100
```

---

## ðŸ“¦ REQUIRED PACKAGES (requirements.txt)

```
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
scikit-learn>=1.3.0
scikit-image>=0.21.0
scipy>=1.10.0
tslearn>=0.6.0          # For DTW clustering
xgboost>=2.0.0          # For gradient boosting
tensorflow>=2.13.0      # For LSTM/GRU
streamlit>=1.28.0       # For dashboard
folium>=0.14.0          # For mapping
geopandas>=0.14.0       # For geospatial data
plotly>=5.15.0          # For interactive plots
tqdm>=4.65.0            # For progress bars
```

---

## ðŸŽ¯ KEY DELIVERABLES CHECKLIST

### âœ… Phase 1
- [x] Loaded real PASTIS data (NO synthetic data)
- [x] Computed NDVI for all patches and timesteps
- [x] Computed EVI for all patches and timesteps
- [x] Normalized using PASTIS statistics
- [x] Exported processed data for Phase 2

### ðŸ”§ Phase 2 (To Implement)
- [ ] Segment parcels using `ParcelIDs_*.npy`
- [ ] Extract temporal features (mean, std, percentiles) per parcel per timestep
- [ ] Compute GLCM texture features (contrast, homogeneity, etc.)
- [ ] Export time-series DataFrame for Phase 3

### ðŸ”§ Phase 3 (To Implement)
- [ ] Implement K-Means with DTW for time-series clustering
- [ ] Implement anomaly detection (Isolation Forest / LOF)
- [ ] Generate cluster assignments and anomaly scores
- [ ] Export patterns for Phase 4

### ðŸ”§ Phase 4 (To Implement)
- [ ] Train Random Forest / XGBoost for baseline
- [ ] Train LSTM / GRU for temporal modeling
- [ ] Evaluate with RMSE (regression) and F1-score (classification)
- [ ] Save trained models

### ðŸ”§ Phase 5 (To Implement)
- [ ] Build Streamlit dashboard
- [ ] Create interactive map with stress heatmap
- [ ] Display NDVI/EVI time-series on plot selection
- [ ] Show predictions and recommendations

---

## ðŸ“š NEXT STEPS

1. **Review Phase 1 Output**: Check `outputs/phase1/phase1_report.txt`
2. **Implement Phase 2**: Update `src/phase2_segmentation.py` using the specifications above
3. **Implement Phase 3**: Update `src/phase3_*` with DTW clustering and Isolation Forest
4. **Create Phase 4**: Build `src/phase4_predictivemodeling.py` with RF/XGBoost + LSTM
5. **Create Phase 5**: Build `src/phase5_dashboard.py` with Streamlit

---

## ðŸ†˜ TROUBLESHOOTING

### Issue: "Module not found"
**Solution**: Install missing package: `pip install <package_name>`

### Issue: "No S2_*.npy files found"
**Solution**: Verify PASTIS data is in `data/PASTIS/DATA_S2/`

### Issue: "UnicodeEncodeError"
**Solution**: Already fixed in `phase1_preprocessing_v2.py` (added `encoding='utf-8'`)

---

## ðŸ“§ CONTACT

For questions about this implementation, contact the project team:
- Rahul Pogula (Phase 1)
- Snehal Teja Adidam (Phase 2)
- Teja Sai Srinivas Kunisetty (Phase 3)
- Lahithya Reddy (Phase 4 & 5)

---

**Generated**: November 12, 2025  
**Project**: CSCE5380 Crop Health Monitoring from Remote Sensing  
**Group**: Group 15
